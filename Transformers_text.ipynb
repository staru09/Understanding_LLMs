{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import pipeline\n\ntranslator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\ntranslator(\"Ce cours est produit par Hugging Face.\")","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:11:48.760183Z","iopub.execute_input":"2024-07-20T13:11:48.760959Z","iopub.status.idle":"2024-07-20T13:12:31.589646Z","shell.execute_reply.started":"2024-07-20T13:11:48.760912Z","shell.execute_reply":"2024-07-20T13:12:31.587972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\nunmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\nresult = unmasker(\"This man works as a [MASK].\")\nprint([r[\"token_str\"] for r in result])\n\nresult = unmasker(\"This woman works as a [MASK].\")\nprint([r[\"token_str\"] for r in result])","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:12:31.591407Z","iopub.execute_input":"2024-07-20T13:12:31.592182Z","iopub.status.idle":"2024-07-20T13:12:38.941192Z","shell.execute_reply.started":"2024-07-20T13:12:31.592146Z","shell.execute_reply":"2024-07-20T13:12:38.940236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\nner = pipeline(\"ner\", grouped_entities=True)\nner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:12:38.944293Z","iopub.execute_input":"2024-07-20T13:12:38.944598Z","iopub.status.idle":"2024-07-20T13:13:03.088747Z","shell.execute_reply.started":"2024-07-20T13:12:38.944571Z","shell.execute_reply":"2024-07-20T13:13:03.087801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:03.091430Z","iopub.execute_input":"2024-07-20T13:13:03.092029Z","iopub.status.idle":"2024-07-20T13:13:03.950685Z","shell.execute_reply.started":"2024-07-20T13:13:03.091971Z","shell.execute_reply":"2024-07-20T13:13:03.949683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_inputs = [\n    \"I've been waiting for a HuggingFace course my whole life.\",\n    \"I hate this so much!\",\n    \"That could be an irony\"\n]\ninputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\nprint(inputs)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:03.951836Z","iopub.execute_input":"2024-07-20T13:13:03.952172Z","iopub.status.idle":"2024-07-20T13:13:03.961351Z","shell.execute_reply.started":"2024-07-20T13:13:03.952135Z","shell.execute_reply":"2024-07-20T13:13:03.959247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModel\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\nmodel = AutoModel.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:03.962646Z","iopub.execute_input":"2024-07-20T13:13:03.962977Z","iopub.status.idle":"2024-07-20T13:13:10.441200Z","shell.execute_reply.started":"2024-07-20T13:13:03.962946Z","shell.execute_reply":"2024-07-20T13:13:10.440327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs = model(**inputs)\nprint(outputs.last_hidden_state.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:10.442334Z","iopub.execute_input":"2024-07-20T13:13:10.444515Z","iopub.status.idle":"2024-07-20T13:13:10.508808Z","shell.execute_reply.started":"2024-07-20T13:13:10.444487Z","shell.execute_reply":"2024-07-20T13:13:10.507856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint)\noutputs = model(**inputs)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:10.509827Z","iopub.execute_input":"2024-07-20T13:13:10.510159Z","iopub.status.idle":"2024-07-20T13:13:15.460975Z","shell.execute_reply.started":"2024-07-20T13:13:10.510132Z","shell.execute_reply":"2024-07-20T13:13:15.460190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(outputs.logits)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:15.462105Z","iopub.execute_input":"2024-07-20T13:13:15.462402Z","iopub.status.idle":"2024-07-20T13:13:15.476127Z","shell.execute_reply.started":"2024-07-20T13:13:15.462376Z","shell.execute_reply":"2024-07-20T13:13:15.475354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\npredictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\nprint(predictions)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:15.479351Z","iopub.execute_input":"2024-07-20T13:13:15.479621Z","iopub.status.idle":"2024-07-20T13:13:15.485211Z","shell.execute_reply.started":"2024-07-20T13:13:15.479597Z","shell.execute_reply":"2024-07-20T13:13:15.484321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.config.id2label","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:15.486310Z","iopub.execute_input":"2024-07-20T13:13:15.486627Z","iopub.status.idle":"2024-07-20T13:13:15.498090Z","shell.execute_reply.started":"2024-07-20T13:13:15.486595Z","shell.execute_reply":"2024-07-20T13:13:15.497352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertConfig, BertModel\n\n# Building the config\nconfig = BertConfig()\n\n# Building the model from the config\nmodel = BertModel(config)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:15.498967Z","iopub.execute_input":"2024-07-20T13:13:15.499239Z","iopub.status.idle":"2024-07-20T13:13:17.405508Z","shell.execute_reply.started":"2024-07-20T13:13:15.499217Z","shell.execute_reply":"2024-07-20T13:13:17.404681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(config)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:17.406620Z","iopub.execute_input":"2024-07-20T13:13:17.406910Z","iopub.status.idle":"2024-07-20T13:13:17.412684Z","shell.execute_reply.started":"2024-07-20T13:13:17.406884Z","shell.execute_reply":"2024-07-20T13:13:17.411783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer\n\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:17.413910Z","iopub.execute_input":"2024-07-20T13:13:17.414310Z","iopub.status.idle":"2024-07-20T13:13:18.465775Z","shell.execute_reply.started":"2024-07-20T13:13:17.414276Z","shell.execute_reply":"2024-07-20T13:13:18.464932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer(\"Using a Transformer network is simple\")","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:18.467362Z","iopub.execute_input":"2024-07-20T13:13:18.467719Z","iopub.status.idle":"2024-07-20T13:13:18.474711Z","shell.execute_reply.started":"2024-07-20T13:13:18.467684Z","shell.execute_reply":"2024-07-20T13:13:18.473536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\nsequence = \"Using a Transformer network is simple\"\ntokens = tokenizer.tokenize(sequence)\nprint(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:18.475892Z","iopub.execute_input":"2024-07-20T13:13:18.476278Z","iopub.status.idle":"2024-07-20T13:13:18.605642Z","shell.execute_reply.started":"2024-07-20T13:13:18.476253Z","shell.execute_reply":"2024-07-20T13:13:18.604765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids = tokenizer.convert_tokens_to_ids(tokens)\nprint(ids)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:18.606917Z","iopub.execute_input":"2024-07-20T13:13:18.607307Z","iopub.status.idle":"2024-07-20T13:13:18.612211Z","shell.execute_reply.started":"2024-07-20T13:13:18.607271Z","shell.execute_reply":"2024-07-20T13:13:18.611286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new = tokenizer.tokenize(\"Using a Transformer network is tough\")\nprint(new)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:18.613413Z","iopub.execute_input":"2024-07-20T13:13:18.613712Z","iopub.status.idle":"2024-07-20T13:13:18.623657Z","shell.execute_reply.started":"2024-07-20T13:13:18.613683Z","shell.execute_reply":"2024-07-20T13:13:18.622769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"news = tokenizer.convert_tokens_to_ids(new)\nprint(news)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:18.624803Z","iopub.execute_input":"2024-07-20T13:13:18.625095Z","iopub.status.idle":"2024-07-20T13:13:18.634124Z","shell.execute_reply.started":"2024-07-20T13:13:18.625071Z","shell.execute_reply":"2024-07-20T13:13:18.633207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decoded_string = tokenizer.decode([7993, 170, 11303, 1200, 2443, 1110, 3014])\nprint(decoded_string)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:18.635055Z","iopub.execute_input":"2024-07-20T13:13:18.635333Z","iopub.status.idle":"2024-07-20T13:13:18.645152Z","shell.execute_reply.started":"2024-07-20T13:13:18.635309Z","shell.execute_reply":"2024-07-20T13:13:18.643814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decoded_string_2 = tokenizer.decode([7993, 170, 11303, 1200, 2443, 1110, 8035])\nprint(decoded_string_2)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:18.646253Z","iopub.execute_input":"2024-07-20T13:13:18.646488Z","iopub.status.idle":"2024-07-20T13:13:18.655452Z","shell.execute_reply.started":"2024-07-20T13:13:18.646468Z","shell.execute_reply":"2024-07-20T13:13:18.654647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_inputs = tokenizer(sequence, return_tensors=\"pt\")\nprint(tokenized_inputs[\"input_ids\"])","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:18.656923Z","iopub.execute_input":"2024-07-20T13:13:18.657252Z","iopub.status.idle":"2024-07-20T13:13:18.667318Z","shell.execute_reply.started":"2024-07-20T13:13:18.657223Z","shell.execute_reply":"2024-07-20T13:13:18.666513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n\nsequence = \"I've been waiting for a HuggingFace course my whole life.\"\n\ntokens = tokenizer.tokenize(sequence)\nids = tokenizer.convert_tokens_to_ids(tokens)\n\ninput_ids = torch.tensor([ids])\nprint(\"Input IDs:\", input_ids)\n\noutput = model(input_ids)\nprint(\"Logits:\", output.logits)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:18.668497Z","iopub.execute_input":"2024-07-20T13:13:18.669229Z","iopub.status.idle":"2024-07-20T13:13:19.085963Z","shell.execute_reply.started":"2024-07-20T13:13:18.669203Z","shell.execute_reply":"2024-07-20T13:13:19.085032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"padding_id = 100\n\nbatched_ids = [\n    [200, 200, 200],\n    [200, 200, padding_id],\n]\n\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n\nsequence1_ids = [[200, 200, 200]]\nsequence2_ids = [[200, 200]]\nbatched_ids = [\n    [200, 200, 200],\n    [200, 200, tokenizer.pad_token_id],\n]\n\nprint(model(torch.tensor(sequence1_ids)).logits)\nprint(model(torch.tensor(sequence2_ids)).logits)\nprint(model(torch.tensor(batched_ids)).logits)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:19.087342Z","iopub.execute_input":"2024-07-20T13:13:19.087769Z","iopub.status.idle":"2024-07-20T13:13:19.331884Z","shell.execute_reply.started":"2024-07-20T13:13:19.087736Z","shell.execute_reply":"2024-07-20T13:13:19.330998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\nsequence = \"I've been waiting for a HuggingFace course my whole life.\"\n\nmodel_inputs = tokenizer(sequence)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:19.333278Z","iopub.execute_input":"2024-07-20T13:13:19.333720Z","iopub.status.idle":"2024-07-20T13:13:19.477145Z","shell.execute_reply.started":"2024-07-20T13:13:19.333685Z","shell.execute_reply":"2024-07-20T13:13:19.476387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequences = [\"I've been waiting for a HuggingFace course my whole life.\", \"So have I!\"]\n\nmodel_inputs = tokenizer(sequences)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:19.478300Z","iopub.execute_input":"2024-07-20T13:13:19.478646Z","iopub.status.idle":"2024-07-20T13:13:19.483650Z","shell.execute_reply.started":"2024-07-20T13:13:19.478613Z","shell.execute_reply":"2024-07-20T13:13:19.482554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Will pad the sequences up to the maximum sequence length\nmodel_inputs = tokenizer(sequences, padding=\"longest\")\n\n# Will pad the sequences up to the model max length\n# (512 for BERT or DistilBERT)\nmodel_inputs = tokenizer(sequences, padding=\"max_length\")\n\n# Will pad the sequences up to the specified max length\nmodel_inputs = tokenizer(sequences, padding=\"max_length\", max_length=8)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:19.485226Z","iopub.execute_input":"2024-07-20T13:13:19.485653Z","iopub.status.idle":"2024-07-20T13:13:19.498257Z","shell.execute_reply.started":"2024-07-20T13:13:19.485616Z","shell.execute_reply":"2024-07-20T13:13:19.497526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequences = [\"I've been waiting for a HuggingFace course my whole life.\", \"So have I!\"]\n\n# Will truncate the sequences that are longer than the model max length\n# (512 for BERT or DistilBERT)\nmodel_inputs = tokenizer(sequences, truncation=True)\n\n# Will truncate the sequences that are longer than the specified max length\nmodel_inputs = tokenizer(sequences, max_length=8, truncation=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:19.504149Z","iopub.execute_input":"2024-07-20T13:13:19.504391Z","iopub.status.idle":"2024-07-20T13:13:19.509544Z","shell.execute_reply.started":"2024-07-20T13:13:19.504370Z","shell.execute_reply":"2024-07-20T13:13:19.508706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequence = \"I've been waiting for a HuggingFace course my whole life.\"\n\nmodel_inputs = tokenizer(sequence)\nprint(model_inputs[\"input_ids\"])\n\ntokens = tokenizer.tokenize(sequence)\nids = tokenizer.convert_tokens_to_ids(tokens)\nprint(ids)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:19.510731Z","iopub.execute_input":"2024-07-20T13:13:19.511344Z","iopub.status.idle":"2024-07-20T13:13:19.519110Z","shell.execute_reply.started":"2024-07-20T13:13:19.511309Z","shell.execute_reply":"2024-07-20T13:13:19.518285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint)\nsequences = [\"I've been waiting for a HuggingFace course my whole life.\", \"So have I!\"]\n\ntokens = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\noutput = model(**tokens)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:19.520237Z","iopub.execute_input":"2024-07-20T13:13:19.520666Z","iopub.status.idle":"2024-07-20T13:13:19.928091Z","shell.execute_reply.started":"2024-07-20T13:13:19.520634Z","shell.execute_reply":"2024-07-20T13:13:19.927256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Chapter 3 **","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification\n\n# Same as before\ncheckpoint = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint)\nsequences = [\n    \"I've been waiting for a HuggingFace course my whole life.\",\n    \"This course is amazing!\",\n]\nbatch = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n\n# This is new\nbatch[\"labels\"] = torch.tensor([1, 1])\n\noptimizer = AdamW(model.parameters())\nloss = model(**batch).loss\nloss.backward()\noptimizer.step()","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:19.929349Z","iopub.execute_input":"2024-07-20T13:13:19.929704Z","iopub.status.idle":"2024-07-20T13:13:21.315205Z","shell.execute_reply.started":"2024-07-20T13:13:19.929669Z","shell.execute_reply":"2024-07-20T13:13:21.314335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\nraw_datasets = load_dataset(\"glue\", \"mrpc\")\nraw_datasets","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:21.316449Z","iopub.execute_input":"2024-07-20T13:13:21.316793Z","iopub.status.idle":"2024-07-20T13:13:29.191617Z","shell.execute_reply.started":"2024-07-20T13:13:21.316761Z","shell.execute_reply":"2024-07-20T13:13:29.190792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_train_dataset = raw_datasets[\"train\"]\nraw_train_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:29.192733Z","iopub.execute_input":"2024-07-20T13:13:29.193278Z","iopub.status.idle":"2024-07-20T13:13:29.203883Z","shell.execute_reply.started":"2024-07-20T13:13:29.193251Z","shell.execute_reply":"2024-07-20T13:13:29.202563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_train_dataset = raw_datasets[\"train\"]\nraw_test_dataset = raw_datasets[\"test\"]","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:29.205098Z","iopub.execute_input":"2024-07-20T13:13:29.205378Z","iopub.status.idle":"2024-07-20T13:13:29.216275Z","shell.execute_reply.started":"2024-07-20T13:13:29.205354Z","shell.execute_reply":"2024-07-20T13:13:29.215296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ncheckpoint = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\ntokenized_sentences_1 = tokenizer(raw_datasets[\"train\"][\"sentence1\"])\ntokenized_sentences_2 = tokenizer(raw_datasets[\"train\"][\"sentence2\"])","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:29.217456Z","iopub.execute_input":"2024-07-20T13:13:29.217743Z","iopub.status.idle":"2024-07-20T13:13:30.052011Z","shell.execute_reply.started":"2024-07-20T13:13:29.217710Z","shell.execute_reply":"2024-07-20T13:13:30.051232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = tokenizer(\"This is the first sentence.\", \"This is the second one.\")\ninputs","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:30.053029Z","iopub.execute_input":"2024-07-20T13:13:30.053283Z","iopub.status.idle":"2024-07-20T13:13:30.059459Z","shell.execute_reply.started":"2024-07-20T13:13:30.053260Z","shell.execute_reply":"2024-07-20T13:13:30.058564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"])","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:30.060392Z","iopub.execute_input":"2024-07-20T13:13:30.060638Z","iopub.status.idle":"2024-07-20T13:13:30.071003Z","shell.execute_reply.started":"2024-07-20T13:13:30.060616Z","shell.execute_reply":"2024-07-20T13:13:30.070151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset = tokenizer(\n    raw_datasets[\"train\"][\"sentence1\"],\n    raw_datasets[\"train\"][\"sentence2\"],\n    padding=True,\n    truncation=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:30.072036Z","iopub.execute_input":"2024-07-20T13:13:30.072284Z","iopub.status.idle":"2024-07-20T13:13:30.794337Z","shell.execute_reply.started":"2024-07-20T13:13:30.072262Z","shell.execute_reply":"2024-07-20T13:13:30.793552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize_function(example):\n    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:30.795436Z","iopub.execute_input":"2024-07-20T13:13:30.795732Z","iopub.status.idle":"2024-07-20T13:13:30.800591Z","shell.execute_reply.started":"2024-07-20T13:13:30.795706Z","shell.execute_reply":"2024-07-20T13:13:30.799557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\ntokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:30.801835Z","iopub.execute_input":"2024-07-20T13:13:30.802275Z","iopub.status.idle":"2024-07-20T13:13:32.215702Z","shell.execute_reply.started":"2024-07-20T13:13:30.802243Z","shell.execute_reply":"2024-07-20T13:13:32.214805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:32.216915Z","iopub.execute_input":"2024-07-20T13:13:32.217280Z","iopub.status.idle":"2024-07-20T13:13:32.221782Z","shell.execute_reply.started":"2024-07-20T13:13:32.217249Z","shell.execute_reply":"2024-07-20T13:13:32.220931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samples = tokenized_datasets[\"train\"][:8]\nsamples = {k: v for k, v in samples.items() if k not in [\"idx\", \"sentence1\", \"sentence2\"]}\n[len(x) for x in samples[\"input_ids\"]]","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:32.223220Z","iopub.execute_input":"2024-07-20T13:13:32.223517Z","iopub.status.idle":"2024-07-20T13:13:32.244642Z","shell.execute_reply.started":"2024-07-20T13:13:32.223494Z","shell.execute_reply":"2024-07-20T13:13:32.243663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch = data_collator(samples)\n{k: v.shape for k, v in batch.items()}","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:32.245638Z","iopub.execute_input":"2024-07-20T13:13:32.245881Z","iopub.status.idle":"2024-07-20T13:13:32.256690Z","shell.execute_reply.started":"2024-07-20T13:13:32.245858Z","shell.execute_reply":"2024-07-20T13:13:32.255931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoTokenizer, DataCollatorWithPadding\n\nraw_datasets = load_dataset(\"glue\", \"mrpc\")\ncheckpoint = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\n\ndef tokenize_function(example):\n    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n\n\ntokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:32.257730Z","iopub.execute_input":"2024-07-20T13:13:32.258002Z","iopub.status.idle":"2024-07-20T13:13:35.957211Z","shell.execute_reply.started":"2024-07-20T13:13:32.257963Z","shell.execute_reply":"2024-07-20T13:13:35.956274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training using Trainer api","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments\ntraining_args = TrainingArguments(\"test-trainer\")","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:35.958508Z","iopub.execute_input":"2024-07-20T13:13:35.959213Z","iopub.status.idle":"2024-07-20T13:13:36.031311Z","shell.execute_reply.started":"2024-07-20T13:13:35.959176Z","shell.execute_reply":"2024-07-20T13:13:36.030376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:36.032583Z","iopub.execute_input":"2024-07-20T13:13:36.033210Z","iopub.status.idle":"2024-07-20T13:13:36.374110Z","shell.execute_reply.started":"2024-07-20T13:13:36.033170Z","shell.execute_reply":"2024-07-20T13:13:36.373362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:36.375280Z","iopub.execute_input":"2024-07-20T13:13:36.375539Z","iopub.status.idle":"2024-07-20T13:13:38.102857Z","shell.execute_reply.started":"2024-07-20T13:13:36.375515Z","shell.execute_reply":"2024-07-20T13:13:38.101917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()\n#d8ded67bb5d5d9b9a148342319df7f0ab97ef45d","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:13:38.104166Z","iopub.execute_input":"2024-07-20T13:13:38.104797Z","iopub.status.idle":"2024-07-20T13:19:34.487902Z","shell.execute_reply.started":"2024-07-20T13:13:38.104761Z","shell.execute_reply":"2024-07-20T13:19:34.487022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = trainer.predict(tokenized_datasets[\"validation\"])\nprint(predictions.predictions.shape, predictions.label_ids.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:19:34.489257Z","iopub.execute_input":"2024-07-20T13:19:34.489550Z","iopub.status.idle":"2024-07-20T13:19:36.458873Z","shell.execute_reply.started":"2024-07-20T13:19:34.489526Z","shell.execute_reply":"2024-07-20T13:19:36.458033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\npreds = np.argmax(predictions.predictions, axis=-1)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:21:35.559721Z","iopub.execute_input":"2024-07-20T13:21:35.560170Z","iopub.status.idle":"2024-07-20T13:21:35.566690Z","shell.execute_reply.started":"2024-07-20T13:21:35.560139Z","shell.execute_reply":"2024-07-20T13:21:35.565716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install evaluate\nimport evaluate\nmetric = evaluate.load(\"glue\", \"mrpc\")\nmetric.compute(predictions=preds, references=predictions.label_ids)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:22:20.006285Z","iopub.execute_input":"2024-07-20T13:22:20.006935Z","iopub.status.idle":"2024-07-20T13:22:34.963838Z","shell.execute_reply.started":"2024-07-20T13:22:20.006900Z","shell.execute_reply":"2024-07-20T13:22:34.962477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(eval_preds):\n    metric = evaluate.load(\"glue\", \"mrpc\")\n    logits, labels = eval_preds\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:23:20.564841Z","iopub.execute_input":"2024-07-20T13:23:20.565525Z","iopub.status.idle":"2024-07-20T13:23:20.571921Z","shell.execute_reply.started":"2024-07-20T13:23:20.565487Z","shell.execute_reply":"2024-07-20T13:23:20.570868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\"test-trainer\", evaluation_strategy=\"epoch\")\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:23:21.899818Z","iopub.execute_input":"2024-07-20T13:23:21.900233Z","iopub.status.idle":"2024-07-20T13:23:22.536852Z","shell.execute_reply.started":"2024-07-20T13:23:21.900200Z","shell.execute_reply":"2024-07-20T13:23:22.535782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:23:25.067818Z","iopub.execute_input":"2024-07-20T13:23:25.068448Z","iopub.status.idle":"2024-07-20T13:26:11.587734Z","shell.execute_reply.started":"2024-07-20T13:23:25.068413Z","shell.execute_reply":"2024-07-20T13:26:11.586841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pytorch Edition of Training Loop","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoTokenizer, DataCollatorWithPadding\n\nraw_datasets = load_dataset(\"glue\", \"mrpc\")\ncheckpoint = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\n\ndef tokenize_function(example):\n    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True, padding=\"max_length\")\n\n\ntokenized_datasets = raw_datasets.map(tokenize_function, batched=True, )\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T14:04:51.502602Z","iopub.execute_input":"2024-07-20T14:04:51.503201Z","iopub.status.idle":"2024-07-20T14:04:57.469410Z","shell.execute_reply.started":"2024-07-20T14:04:51.503167Z","shell.execute_reply":"2024-07-20T14:04:57.468255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = tokenized_datasets.remove_columns([\"sentence1\", \"sentence2\", \"idx\"])\ntokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\ntokenized_datasets.set_format(\"torch\")\ntokenized_datasets[\"train\"].column_names","metadata":{"execution":{"iopub.status.busy":"2024-07-20T14:05:03.239760Z","iopub.execute_input":"2024-07-20T14:05:03.240211Z","iopub.status.idle":"2024-07-20T14:05:03.264208Z","shell.execute_reply.started":"2024-07-20T14:05:03.240179Z","shell.execute_reply":"2024-07-20T14:05:03.263380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataloader = DataLoader(\n    tokenized_datasets[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n)\neval_dataloader = DataLoader(\n    tokenized_datasets[\"validation\"], batch_size=8, collate_fn=data_collator\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T14:05:06.851508Z","iopub.execute_input":"2024-07-20T14:05:06.851868Z","iopub.status.idle":"2024-07-20T14:05:06.859014Z","shell.execute_reply.started":"2024-07-20T14:05:06.851841Z","shell.execute_reply":"2024-07-20T14:05:06.857812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch in train_dataloader:\n    break\n{k: v.shape for k, v in batch.items()}","metadata":{"execution":{"iopub.status.busy":"2024-07-20T14:05:09.371628Z","iopub.execute_input":"2024-07-20T14:05:09.372325Z","iopub.status.idle":"2024-07-20T14:05:09.390840Z","shell.execute_reply.started":"2024-07-20T14:05:09.372274Z","shell.execute_reply":"2024-07-20T14:05:09.389854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T14:05:16.129744Z","iopub.execute_input":"2024-07-20T14:05:16.130541Z","iopub.status.idle":"2024-07-20T14:05:16.390843Z","shell.execute_reply.started":"2024-07-20T14:05:16.130504Z","shell.execute_reply":"2024-07-20T14:05:16.390124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs = model(**batch)\nprint(outputs.loss, outputs.logits.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T14:05:17.382965Z","iopub.execute_input":"2024-07-20T14:05:17.383339Z","iopub.status.idle":"2024-07-20T14:05:22.840589Z","shell.execute_reply.started":"2024-07-20T14:05:17.383310Z","shell.execute_reply":"2024-07-20T14:05:22.839535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW\n\noptimizer = AdamW(model.parameters(), lr=5e-5)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T14:05:22.842138Z","iopub.execute_input":"2024-07-20T14:05:22.842420Z","iopub.status.idle":"2024-07-20T14:05:22.851060Z","shell.execute_reply.started":"2024-07-20T14:05:22.842395Z","shell.execute_reply":"2024-07-20T14:05:22.850317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import get_scheduler\nnum_epochs = 3\nnum_training_steps = num_epochs * len(train_dataloader)\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps,\n)\nprint(num_training_steps)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T14:05:23.085089Z","iopub.execute_input":"2024-07-20T14:05:23.085385Z","iopub.status.idle":"2024-07-20T14:05:23.093343Z","shell.execute_reply.started":"2024-07-20T14:05:23.085361Z","shell.execute_reply":"2024-07-20T14:05:23.091875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel.to(device)\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-07-20T14:05:24.332293Z","iopub.execute_input":"2024-07-20T14:05:24.333151Z","iopub.status.idle":"2024-07-20T14:05:24.450724Z","shell.execute_reply.started":"2024-07-20T14:05:24.333117Z","shell.execute_reply":"2024-07-20T14:05:24.449734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\nprogress_bar = tqdm(range(num_training_steps))\n\nmodel.train()\nfor epoch in range(num_epochs):\n    for batch in train_dataloader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n        loss.backward()\n\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:50:07.655794Z","iopub.execute_input":"2024-07-20T13:50:07.656162Z","iopub.status.idle":"2024-07-20T13:52:57.348940Z","shell.execute_reply.started":"2024-07-20T13:50:07.656134Z","shell.execute_reply":"2024-07-20T13:52:57.347941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"glue\", \"mrpc\")\nmodel.eval()\nfor batch in eval_dataloader:\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model(**batch)\n\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n\nmetric.compute()","metadata":{"execution":{"iopub.status.busy":"2024-07-20T13:53:38.878195Z","iopub.execute_input":"2024-07-20T13:53:38.879159Z","iopub.status.idle":"2024-07-20T13:53:41.297751Z","shell.execute_reply.started":"2024-07-20T13:53:38.879120Z","shell.execute_reply":"2024-07-20T13:53:41.296630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Summarized here***\nfor accelerated training","metadata":{}},{"cell_type":"code","source":"from transformers import AdamW, AutoModelForSequenceClassification, get_scheduler\nfrom accelerate import Accelerator\n\naccelerator = Accelerator()\n\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\noptimizer = AdamW(model.parameters(), lr=3e-5)\n\ntrain_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(train_dataloader, eval_dataloader, model, optimizer)\n\nnum_epochs = 3\nnum_training_steps = num_epochs * len(train_dataloader)\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps,\n)\n\nprogress_bar = tqdm(range(num_training_steps))\n\nmodel.train()\nfor epoch in range(num_epochs):\n    for batch in train_dataloader:\n        #batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n        accelerator.backward(loss)\n\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T14:05:32.525563Z","iopub.execute_input":"2024-07-20T14:05:32.526186Z","iopub.status.idle":"2024-07-20T14:22:35.355147Z","shell.execute_reply.started":"2024-07-20T14:05:32.526152Z","shell.execute_reply":"2024-07-20T14:22:35.353903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"glue\", \"mrpc\")\nmodel.eval()\nfor batch in eval_dataloader:\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model(**batch)\n\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n\nmetric.compute()","metadata":{"execution":{"iopub.status.busy":"2024-07-20T14:28:41.933515Z","iopub.execute_input":"2024-07-20T14:28:41.933863Z","iopub.status.idle":"2024-07-20T14:28:53.600119Z","shell.execute_reply.started":"2024-07-20T14:28:41.933837Z","shell.execute_reply":"2024-07-20T14:28:53.599161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CTC (Connectionist Temporal Classification)\nEncoder only\n\n1. The key to the CTC algorithm is using a special token, often called the blank token. This is just another token that the model will predict and it’s part of the vocabulary. In this example, the blank token is shown as _. This special token serves as a hard boundary between groups of characters.\n\nThe full output from the CTC model might be something like the following:\n\nB_R_II_O_N_||_S_AWW_|||||_S_OMEE_TH_ING_||_C_L_O_S_E||TO|_P_A_N_I_C_||_ON||HHI_S||_OP_P_O_N_EN_T_'SS||_F_AA_C_E||_W_H_EN||THE||M_A_NN_||||_F_I_N_AL_LL_Y||||_RREE_C_O_GG_NN_II_Z_ED|||HHISS|||_ER_RRR_ORR||||\nThe | token is the word separator character. In the example we use | instead of a space making it easier to spot where the word breaks are, but it serves the same purpose.\n\n2. The CTC blank character makes it possible to filter out the duplicate characters. For example let’s look at the last word from the predicted sequence, _ER_RRR_ORR. Without the CTC blank token, the word looked like this:\n\nERRRRORR\nIf we were to simply remove duplicate characters, this would become EROR. That’s clearly not the correct spelling. But with the CTC blank token we can remove the duplicates in each group, so that:\n\n\n_ER_RRR_ORR\nbecomes:\n\n\n_ER_R_OR\nand now we remove the _ blank token to get the final word:\n\n\nERROR\n\n\n3. To recap, the model predicts one token (character) for every 20 ms of (partially overlapping) audio from the input waveform. This gives a lot of duplicates. Thanks to the CTC blank token, we can easily remove these duplicates without destroying the proper spelling of the words. This is a very simple and convenient way to solve the problem of aligning the output text with the input audio.\n\n4. M-CTC-T, for example, is trained for multilingual speech recognition, and therefore has a relatively large CTC head that includes Chinese characters in addition to other alphabets.","metadata":{}},{"cell_type":"markdown","source":"# Seq2Seq architectures\n\n1. When we also add the decoder to create an encoder-decoder model, this is referred to as a sequence-to-sequence model or seq2seq for short. The model maps a sequence of one kind of data to a sequence of another kind of data.\n\n2. With a seq2seq model, there is no such one-to-one correspondence and the input and output sequences can have different lengths. That makes seq2seq models suitable for NLP tasks such as text summarization or translation between different languages — but also for audio tasks such as speech recognition.\n\n3. For example in Whisper, The decoder predicts a sequence of text tokens in an autoregressive manner, a single token at a time, starting from an initial sequence that just has a “start” token in it (SOT in the case of Whisper). At each following timestep, the previous output sequence is fed back into the decoder as the new input sequence. In this manner, the decoder emits one new token at a time, steadily growing the output sequence, until it predicts an “end” token or a maximum number of timesteps is reached.\n\n4. While the architecture of the decoder is mostly identical to that of the encoder, there are two big differences:\n\n1. The decoder has a cross-attention mechanism that allows it to look at the encoder’s representation of the input sequence \n2. The decoder’s attention is causal — the decoder isn’t allowed to look into the future.\n\n\n7. What makes TTS difficult is that it’s a one-to-many mapping. With speech-to-text there is only one correct output text that corresponds to the input speech, but with text-to-speech the input text can be mapped to many possible speech sounds. Different speakers may choose to emphasize different parts of the sentence, for example. This makes TTS models hard to evaluate. Because of this, the L1 or MSE loss value isn’t actually very meaningful — there are multiple ways to represent the same text to a spectrogram. This is why TTS models are typically evaluated by human listeners, using a metric known as MOS or mean opinion score.\n","metadata":{}},{"cell_type":"markdown","source":"#  Audio Spectrogram Transformer\n\n1.  AST model splits the audio spectrogram into a sequence of partially overlapping image patches of 16×16 pixels. This sequence of patches is then projected into a sequence of embeddings, and these are given to the transformer encoder as input as usual. AST is an encoder-only transformer model and so the output is a sequence of hidden-states, one for each 16×16 input patch. On top of this is a simple classification layer with sigmoid activation to map the hidden-states to classification probabilities.\n\n2. In fact, any encoder-only audio transformer model can be turned into an audio classifier by adding a classification layer on top of the sequence of hidden states. (Classifiers usually don’t need a transformer decoder.)\n\n3. To predict a single classification score for the entire sequence (Wav2Vec2ForSequenceClassification), the model takes the mean over the hidden-states and feeds that into the classification layer. The output is a single probability distribution.\n\n4. To make a separate classification for each audio frame (Wav2Vec2ForAudioFrameClassification), the classifier is run on the sequence of hidden-states, and so the output of the classifier is a sequence too.","metadata":{}},{"cell_type":"markdown","source":"# Evaluation Metrics\n\n[Blog_post](http://https://huggingface.co/learn/audio-course/chapter5/evaluation)\n\nTo_do\n\n1. https://huggingface.co/learn/audio-course/chapter4/hands_on\n2. https://huggingface.co/learn/audio-course/chapter5/hands_on","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}